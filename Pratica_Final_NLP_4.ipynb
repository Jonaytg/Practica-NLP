{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica Final de NLP"
      ],
      "metadata": {
        "id": "CRzRPibL2ckO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Reporte de métricas y conclusiones"
      ],
      "metadata": {
        "id": "uSMpAEVs7VQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.a. Modelo de Machine Learning - Logistic Regression"
      ],
      "metadata": {
        "id": "qzSEmkp07b4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cargamos el modelo"
      ],
      "metadata": {
        "id": "dVVZ_cmp7ih8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "cache_dir = '/content/drive/My Drive/0. KEEPCODING/NLP/'\n",
        "model_file = \"ML_model.h5\"\n",
        "model = load_model(os.path.join(cache_dir, model_file))"
      ],
      "metadata": {
        "id": "rdBiR60G7h2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Evaluamos el modelo"
      ],
      "metadata": {
        "id": "HlCYInWC7nj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(x_test)\n",
        "\n",
        "# Métricas finales\n",
        "print(\"Accuracy en test:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fArldSIQ7XdB",
        "outputId": "32437c6b-fffe-4dab-f23e-6cbb33f92291"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en test: 0.86\n",
            "\n",
            "Reporte de clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86        75\n",
            "           1       0.85      0.88      0.86        75\n",
            "\n",
            "    accuracy                           0.86       150\n",
            "   macro avg       0.86      0.86      0.86       150\n",
            "weighted avg       0.86      0.86      0.86       150\n",
            "\n",
            "\n",
            "Matriz de confusión:\n",
            " [[63 12]\n",
            " [ 9 66]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.b. Modelo de Deep Learning - LSTM"
      ],
      "metadata": {
        "id": "_VC3dKxC8pAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cargamos el modelo"
      ],
      "metadata": {
        "id": "TXqWPEwh8yhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "cache_dir = '/content/drive/My Drive/0. KEEPCODING/NLP/'\n",
        "model_file = \"DL_model.h5\"\n",
        "model = load_model(os.path.join(cache_dir, model_file))"
      ],
      "metadata": {
        "id": "0yHQSGlB7hG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Evaluamos el modelo"
      ],
      "metadata": {
        "id": "1pZfBRPV80Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", scores[0])"
      ],
      "metadata": {
        "id": "9GXftOO381A6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72266f3c-4d4d-4cec-b909-e608e22332b6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6931491494178772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.c. Conclusiones"
      ],
      "metadata": {
        "id": "wWtjwnNy81k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta práctica ha sido principalmente practicar la manipulación y transformación de texto, así como su utilización para generar modelos tanto de Machine Learning como de Deep Learning. Pero el objetivo nunca fue obtener un modelo perfectamente funcional con unos resultados sobresalientes.\n",
        "Esto se debe principalmente a la limitación en procesamiento, obligándonos a trabajar con una cantidad de datos reducida.\n",
        "Además, la fase de preprocesamiento debería ser mucho más extensa y meticulosa, filtrando mayor cantidad de palabras entre otros.\n",
        "A pesar de ello, con las herramientas de las que disponemos, se ha tratado de conseguir los mejores resultados posibles.\n",
        "Por un lado, el modelo de Machine Learning mediante Logistic Regression nos ha ofrecido unos resultados bastante buenos, con una precisión del 0.85 para reviews negativas y 0.88 para reviews positivas, lo cual supone un buen porcentaje de acierto, y en ambos casos con un f1-score de 0.88.\n",
        "Por otro lado, el modelo de Deep Learning no ha obtenido unos resultados tan notables, aunque sí aceptables dadas las condiciones, con un accuracy cercano a 0.7.\n",
        "En definitiva, considerando los recursos que disponemos y basándonos en los resultados, sería más conveniente centrarnos en mejorar el modelo de Machine Learning debido a su simplicidad y efectividad. No obstante, con más tiempo y recursos sería muy recomendable seguir trabajando con el modelo de Deep Learning. Esto se debe a que trabajando con mayor precisión la fase de preprocesamiento, y aumentando la capacidad del modelo mediante la adición de capas neuronales y modificación de otros hiperparámetros, considero que se podrían obtener resultados mucho mejores."
      ],
      "metadata": {
        "id": "g0iLMYzN85am"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vAIvAaYHYLPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}